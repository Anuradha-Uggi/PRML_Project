{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "prml_decreasing_filterswithLayers.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5HI3S-JZ1Yj7",
        "outputId": "91a9ec37-2e18-4de9-e90a-3ac274ae915c"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive',force_remount=True)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JGq7edQJ1lhx",
        "outputId": "bd9c4b7c-af8c-4745-b8e5-8f491b1c3422"
      },
      "source": [
        " %pip install idx2numpy  #To convert standard IDX format MNIST by \"yan Lacun\" into numpy array"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting idx2numpy\n",
            "  Downloading idx2numpy-1.2.3.tar.gz (6.8 kB)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from idx2numpy) (1.19.5)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from idx2numpy) (1.15.0)\n",
            "Building wheels for collected packages: idx2numpy\n",
            "  Building wheel for idx2numpy (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for idx2numpy: filename=idx2numpy-1.2.3-py3-none-any.whl size=7918 sha256=35dc0762f549cb905974df67d5a0b7507347e7d94ceaad88aa91d94383bedb4e\n",
            "  Stored in directory: /root/.cache/pip/wheels/1a/ce/ad/d5e95a35cfe34149aade5e500f2edd535c0566d79e9a8e1d8a\n",
            "Successfully built idx2numpy\n",
            "Installing collected packages: idx2numpy\n",
            "Successfully installed idx2numpy-1.2.3\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xwxJVV7k2CZp"
      },
      "source": [
        " \n",
        "import pandas\n",
        "from keras.models import Sequential #swquential is for plain stack of layers with each having one i/p and one o/p\n",
        "from keras.layers import Dense\n",
        "#from keras.wrappers.scikit_learn import KerasClassifier\n",
        "from keras.utils import np_utils\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.model_selection import KFold\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.pipeline import Pipeline\n",
        "from keras.layers import Dense, Dropout, Flatten\n",
        "from keras.layers import Conv2D, MaxPooling2D"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0mqxKt9j2ENJ",
        "outputId": "0d6643e7-5dbc-4cf5-b2b8-9845ae979583"
      },
      "source": [
        "import idx2numpy\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from numpy import linalg as LA\n",
        " \n",
        "## Importing the dataset present in the drive into a numpy array\n",
        "# Importing the 112800 training images (28x28)\n",
        "X_train = idx2numpy.convert_from_file('/content/drive/MyDrive/PRML/Project/MNIST_data/gzip/emnist-balanced-train-images-idx3-ubyte')### 60k training images each with 784 pixel elements \n",
        "# Importing the 112800 training labels\n",
        "Y_train = idx2numpy.convert_from_file('/content/drive/MyDrive/PRML/Project/MNIST_data/gzip/emnist-balanced-train-labels-idx1-ubyte')#### labels--digits for each training image among 60k\n",
        "# Importing the 18800 testing images (28x28)\n",
        "X_test=idx2numpy.convert_from_file('/content/drive/MyDrive/PRML/Project/MNIST_data/gzip/emnist-balanced-test-images-idx3-ubyte')\n",
        "# Importing the 18800 testing Labels\n",
        "Y_test=idx2numpy.convert_from_file('/content/drive/MyDrive/PRML/Project/MNIST_data/gzip/emnist-balanced-test-labels-idx1-ubyte')\n",
        " \n",
        " \n",
        "print('\\ntrain images:',X_train.shape)\n",
        "print('train labels:',Y_train.shape)\n",
        "print('test images:',X_test.shape)\n",
        "print('test labels:',Y_test.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "train images: (112800, 28, 28)\n",
            "train labels: (112800,)\n",
            "test images: (18800, 28, 28)\n",
            "test labels: (18800,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eSZxrg-O2L_5"
      },
      "source": [
        "X_train=X_train.reshape((X_train.shape[0],28,28,1)).astype('float32')\n",
        "X_test=X_test.reshape((X_test.shape[0],28,28,1)).astype('float32')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "55jrdFGp2Pm-",
        "outputId": "127f8d9f-30a7-4f21-8d7c-60e06c096932"
      },
      "source": [
        " y_1hot=np_utils.to_categorical(Y_train)\n",
        "print(y_1hot)\n",
        "y_1hotTest=np_utils.to_categorical(Y_test)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[0. 0. 0. ... 0. 1. 0.]\n",
            " [0. 0. 0. ... 0. 0. 0.]\n",
            " [0. 0. 0. ... 0. 0. 0.]\n",
            " ...\n",
            " [0. 0. 0. ... 0. 0. 0.]\n",
            " [0. 0. 0. ... 0. 0. 0.]\n",
            " [0. 0. 0. ... 0. 0. 0.]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zexPfSZc2UqY"
      },
      "source": [
        "layers=[0,1,2,3,4,5]\n",
        "filters=[64,32,16,8,4]\n",
        "Tacrcy=[];\n",
        "Vacrcy=[];\n",
        "e=10\n",
        "for l in layers:\n",
        "         \n",
        "        model=Sequential()\n",
        "        #initial layer\n",
        "        model.add(Conv2D(128,kernel_size=(3,3),input_shape=(28,28,1),activation='relu'))\n",
        "        \n",
        "        ##stack of subsequrnt layers \n",
        "        if l>0:\n",
        "            for i in range(0,int(l)):\n",
        "                model.add(Conv2D(filters[i],kernel_size=(3,3),activation='relu'))\n",
        "        model.add(MaxPooling2D(pool_size=(2,2),strides=(1,1),padding='valid'))\n",
        "     \n",
        "        model.add(Flatten())\n",
        " \n",
        "        model.add(Dense(15000,activation='relu',name='i/p-layer'))\n",
        "        model.add(Dense(47,activation='softmax',name='o/p-layer'))\n",
        " \n",
        "        model.compile(loss='categorical_crossentropy',optimizer='sgd',metrics=['accuracy'])\n",
        "        hit=model.fit(X_train,y_1hot,epochs=e,validation_split=0.33,batch_size=64,verbose=1)\n",
        "        k=hit.history\n",
        "        Tacrcy.append(k['accuracy'][e-1])\n",
        "        Vacrcy.append(k['val_accuracy'][e-1])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dreN4FEeARYZ"
      },
      "source": [
        "print(Tacrcy,Vacrcy)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fdRH_LfKfllz"
      },
      "source": [
        "#Tacrcy=[0.8152:(128,64,32),0.6528:(128,64)(35min),0.9070724248886108:(128)]\n",
        "#Vacrcy=[0.8015:(128,64,32),0.6813:(128,64),0.8172733187675476:(128)]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7JHM1hqHAfAR"
      },
      "source": [
        "l=[1,2,3,4,5,6]\n",
        "plt.figure(1)\n",
        "plt.plot(l,Tacrcy,color='g',marker='o',linestyle='dashed')\n",
        "plt.plot(l,Vacrcy,color='r',marker='o',linestyle='dashed')\n",
        "plt.xlabel('No.of Conv Layers')\n",
        "plt.ylabel('accuracy')\n",
        "plt.title('Kernels:4,8,16,32,64,128')\n",
        "plt.legend(['Training','Validation'])\n",
        "plt.grid()"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}