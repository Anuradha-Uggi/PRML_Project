{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Fine_Conv@Prml.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5HI3S-JZ1Yj7",
        "outputId": "669a0ba1-d87e-47a5-b57b-5c4d7f95a76f"
      },
      "source": [
        " \n",
        " \n",
        " \n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive',force_remount=True)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JGq7edQJ1lhx",
        "outputId": "8e027d2c-62c2-4c1e-a6c4-33a1ea3e2897"
      },
      "source": [
        " %pip install idx2numpy  #To convert standard IDX format MNIST by \"yan Lacun\" into numpy array"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting idx2numpy\n",
            "  Downloading https://files.pythonhosted.org/packages/7e/6b/80628f6cc2f44d80b27f1ef7b57b257ed4c73766113b77d13ad110c091b4/idx2numpy-1.2.3.tar.gz\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from idx2numpy) (1.19.5)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from idx2numpy) (1.15.0)\n",
            "Building wheels for collected packages: idx2numpy\n",
            "  Building wheel for idx2numpy (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for idx2numpy: filename=idx2numpy-1.2.3-cp37-none-any.whl size=7920 sha256=de887a0a1816336cf6b13061fb91633e0f72a2cbdbe3081d97c2b16f8b48a75e\n",
            "  Stored in directory: /root/.cache/pip/wheels/7a/c1/da/284ce80a748fab898b8d1fa95468a386e7cf3b81da18511f9d\n",
            "Successfully built idx2numpy\n",
            "Installing collected packages: idx2numpy\n",
            "Successfully installed idx2numpy-1.2.3\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xwxJVV7k2CZp"
      },
      "source": [
        " \n",
        "import pandas\n",
        "from keras.models import Sequential #swquential is for plain stack of layers with each having one i/p and one o/p\n",
        "from keras.layers import Dense\n",
        "#from keras.wrappers.scikit_learn import KerasClassifier\n",
        "from keras.utils import np_utils\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.model_selection import KFold\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.pipeline import Pipeline\n",
        "from keras.layers import Dense, Dropout, Flatten\n",
        "from keras.layers import Conv2D, MaxPooling2D"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0mqxKt9j2ENJ",
        "outputId": "61b6a156-15b2-4fe0-8069-5fdfd20a5f5e"
      },
      "source": [
        " import idx2numpy\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from numpy import linalg as LA\n",
        " \n",
        "X_train = idx2numpy.convert_from_file('/content/drive/MyDrive/balancedMNIST/emnist-balanced-train-images-idx3-ubyte')### 60k training images each with 784 pixel elements \n",
        "Y_train = idx2numpy.convert_from_file('/content/drive/MyDrive/balancedMNIST/emnist-balanced-train-labels-idx1-ubyte')#### labels--digits for each training image among 60k\n",
        "X_test=idx2numpy.convert_from_file('/content/drive/MyDrive/balancedMNIST/emnist-balanced-test-images-idx3-ubyte')\n",
        "Y_test=idx2numpy.convert_from_file('/content/drive/MyDrive/balancedMNIST/emnist-balanced-test-labels-idx1-ubyte')\n",
        " \n",
        " \n",
        "print('\\ntrain images:',X_train.shape)\n",
        "print('train labels:',Y_train.shape)\n",
        "print('test images:',X_test.shape)\n",
        "print('test labels:',Y_test.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "train images: (112800, 28, 28)\n",
            "train labels: (112800,)\n",
            "test images: (18800, 28, 28)\n",
            "test labels: (18800,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eSZxrg-O2L_5"
      },
      "source": [
        "X_train=X_train.reshape((X_train.shape[0],28,28,1)).astype('float32')\n",
        "X_test=X_test.reshape((X_test.shape[0],28,28,1)).astype('float32')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "55jrdFGp2Pm-",
        "outputId": "570bf650-b800-4caa-fc46-ac164844049a"
      },
      "source": [
        " y_1hot=np_utils.to_categorical(Y_train)\n",
        "print(y_1hot)\n",
        "y_1hotTest=np_utils.to_categorical(Y_test)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[0. 0. 0. ... 0. 1. 0.]\n",
            " [0. 0. 0. ... 0. 0. 0.]\n",
            " [0. 0. 0. ... 0. 0. 0.]\n",
            " ...\n",
            " [0. 0. 0. ... 0. 0. 0.]\n",
            " [0. 0. 0. ... 0. 0. 0.]\n",
            " [0. 0. 0. ... 0. 0. 0.]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZeNvTJonm34k"
      },
      "source": [
        " def Conv_OCR_Model():\n",
        "     model=Sequential()\n",
        "     model.add(Conv2D(16,kernel_size=(3,3),input_shape=(28,28,1),activation='relu'))\n",
        "     model.add(MaxPooling2D(pool_size=(2,2),strides=None,padding='valid'))\n",
        "    # model.add(Dropout(0.5))\n",
        "     model.add(Flatten())\n",
        " \n",
        "     model.add(Dense(1500,activation='relu',name='i/p-layer'))\n",
        "     model.add(Dense(1500,activation='relu',name='hidden-layer'))\n",
        "     model.add(Dense(47,activation='softmax',name='o/p-layer'))\n",
        " \n",
        "     model.compile(loss='categorical_crossentropy',optimizer='sgd',metrics=['accuracy'])\n",
        "     return model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "PORx1SlEOIRu",
        "outputId": "faf75a22-b7bb-4236-fe5d-338326d79034"
      },
      "source": [
        "model=Conv_OCR_Model()\n",
        "hit=model.fit(X_train,y_1hot,epochs=150,batch_size=256,validation_split=0.33,verbose=1)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/150\n",
            "296/296 [==============================] - 77s 210ms/step - loss: 4.7654 - accuracy: 0.0256 - val_loss: 3.8492 - val_accuracy: 0.0427\n",
            "Epoch 2/150\n",
            "296/296 [==============================] - 62s 209ms/step - loss: 3.8489 - accuracy: 0.0437 - val_loss: 3.8476 - val_accuracy: 0.0502\n",
            "Epoch 3/150\n",
            "296/296 [==============================] - 62s 209ms/step - loss: 3.8467 - accuracy: 0.0506 - val_loss: 3.8450 - val_accuracy: 0.0677\n",
            "Epoch 4/150\n",
            "296/296 [==============================] - 62s 209ms/step - loss: 3.8426 - accuracy: 0.0527 - val_loss: 3.8344 - val_accuracy: 0.0358\n",
            "Epoch 5/150\n",
            "296/296 [==============================] - 62s 209ms/step - loss: 3.8214 - accuracy: 0.0447 - val_loss: 3.3162 - val_accuracy: 0.1945\n",
            "Epoch 6/150\n",
            "296/296 [==============================] - 62s 209ms/step - loss: 2.2631 - accuracy: 0.3984 - val_loss: 1.7533 - val_accuracy: 0.5609\n",
            "Epoch 7/150\n",
            "296/296 [==============================] - 62s 209ms/step - loss: 1.1375 - accuracy: 0.6701 - val_loss: 1.1994 - val_accuracy: 0.6553\n",
            "Epoch 8/150\n",
            "296/296 [==============================] - 62s 209ms/step - loss: 0.8350 - accuracy: 0.7463 - val_loss: 1.0426 - val_accuracy: 0.7011\n",
            "Epoch 9/150\n",
            "296/296 [==============================] - 62s 209ms/step - loss: 0.6833 - accuracy: 0.7896 - val_loss: 1.1265 - val_accuracy: 0.6898\n",
            "Epoch 10/150\n",
            "296/296 [==============================] - 62s 210ms/step - loss: 0.5568 - accuracy: 0.8236 - val_loss: 0.9657 - val_accuracy: 0.7129\n",
            "Epoch 11/150\n",
            "296/296 [==============================] - 62s 210ms/step - loss: 0.4604 - accuracy: 0.8511 - val_loss: 0.9658 - val_accuracy: 0.7356\n",
            "Epoch 12/150\n",
            "296/296 [==============================] - 62s 210ms/step - loss: 0.3844 - accuracy: 0.8723 - val_loss: 0.9862 - val_accuracy: 0.7353\n",
            "Epoch 13/150\n",
            "296/296 [==============================] - 62s 210ms/step - loss: 0.3299 - accuracy: 0.8885 - val_loss: 0.9324 - val_accuracy: 0.7611\n",
            "Epoch 14/150\n",
            "296/296 [==============================] - 62s 209ms/step - loss: 0.2655 - accuracy: 0.9100 - val_loss: 1.0708 - val_accuracy: 0.7337\n",
            "Epoch 15/150\n",
            "296/296 [==============================] - 62s 210ms/step - loss: 0.2281 - accuracy: 0.9216 - val_loss: 0.9637 - val_accuracy: 0.7601\n",
            "Epoch 16/150\n",
            "296/296 [==============================] - 62s 210ms/step - loss: 0.1837 - accuracy: 0.9364 - val_loss: 1.1796 - val_accuracy: 0.7355\n",
            "Epoch 17/150\n",
            "296/296 [==============================] - 62s 211ms/step - loss: 0.1560 - accuracy: 0.9455 - val_loss: 1.0666 - val_accuracy: 0.7577\n",
            "Epoch 18/150\n",
            "296/296 [==============================] - 62s 211ms/step - loss: 0.1253 - accuracy: 0.9567 - val_loss: 1.5099 - val_accuracy: 0.7159\n",
            "Epoch 19/150\n",
            "296/296 [==============================] - 62s 210ms/step - loss: 0.1174 - accuracy: 0.9603 - val_loss: 1.2948 - val_accuracy: 0.7491\n",
            "Epoch 20/150\n",
            "296/296 [==============================] - 62s 210ms/step - loss: 0.0962 - accuracy: 0.9655 - val_loss: 1.2940 - val_accuracy: 0.7486\n",
            "Epoch 21/150\n",
            "296/296 [==============================] - 62s 210ms/step - loss: 0.0765 - accuracy: 0.9743 - val_loss: 1.2955 - val_accuracy: 0.7576\n",
            "Epoch 22/150\n",
            "296/296 [==============================] - 62s 211ms/step - loss: 0.0669 - accuracy: 0.9764 - val_loss: 1.2353 - val_accuracy: 0.7695\n",
            "Epoch 23/150\n",
            "296/296 [==============================] - 62s 210ms/step - loss: 0.0564 - accuracy: 0.9802 - val_loss: 1.2465 - val_accuracy: 0.7739\n",
            "Epoch 24/150\n",
            "296/296 [==============================] - 62s 211ms/step - loss: 0.0459 - accuracy: 0.9831 - val_loss: 1.3543 - val_accuracy: 0.7658\n",
            "Epoch 25/150\n",
            "296/296 [==============================] - 62s 210ms/step - loss: 0.0423 - accuracy: 0.9842 - val_loss: 1.3123 - val_accuracy: 0.7717\n",
            "Epoch 26/150\n",
            "296/296 [==============================] - 62s 210ms/step - loss: 0.0368 - accuracy: 0.9869 - val_loss: 1.3355 - val_accuracy: 0.7751\n",
            "Epoch 27/150\n",
            "296/296 [==============================] - 63s 211ms/step - loss: 0.0314 - accuracy: 0.9886 - val_loss: 1.4112 - val_accuracy: 0.7698\n",
            "Epoch 28/150\n",
            "296/296 [==============================] - 62s 209ms/step - loss: 0.0310 - accuracy: 0.9888 - val_loss: 1.4086 - val_accuracy: 0.7721\n",
            "Epoch 29/150\n",
            "296/296 [==============================] - 62s 209ms/step - loss: 0.0268 - accuracy: 0.9907 - val_loss: 1.4114 - val_accuracy: 0.7760\n",
            "Epoch 30/150\n",
            "296/296 [==============================] - 61s 208ms/step - loss: 0.0235 - accuracy: 0.9919 - val_loss: 1.4497 - val_accuracy: 0.7747\n",
            "Epoch 31/150\n",
            "296/296 [==============================] - 62s 208ms/step - loss: 0.0236 - accuracy: 0.9918 - val_loss: 1.4635 - val_accuracy: 0.7749\n",
            "Epoch 32/150\n",
            "296/296 [==============================] - 62s 208ms/step - loss: 0.0211 - accuracy: 0.9929 - val_loss: 1.4903 - val_accuracy: 0.7754\n",
            "Epoch 33/150\n",
            "296/296 [==============================] - 62s 209ms/step - loss: 0.0196 - accuracy: 0.9932 - val_loss: 1.5611 - val_accuracy: 0.7741\n",
            "Epoch 34/150\n",
            "296/296 [==============================] - 62s 209ms/step - loss: 0.0204 - accuracy: 0.9934 - val_loss: 1.5706 - val_accuracy: 0.7722\n",
            "Epoch 35/150\n",
            "296/296 [==============================] - 62s 208ms/step - loss: 0.0175 - accuracy: 0.9943 - val_loss: 1.5716 - val_accuracy: 0.7737\n",
            "Epoch 36/150\n",
            "296/296 [==============================] - 62s 208ms/step - loss: 0.0150 - accuracy: 0.9951 - val_loss: 1.5956 - val_accuracy: 0.7752\n",
            "Epoch 37/150\n",
            "296/296 [==============================] - 62s 209ms/step - loss: 0.0156 - accuracy: 0.9953 - val_loss: 1.6421 - val_accuracy: 0.7743\n",
            "Epoch 38/150\n",
            "296/296 [==============================] - 62s 209ms/step - loss: 0.0170 - accuracy: 0.9949 - val_loss: 1.6296 - val_accuracy: 0.7721\n",
            "Epoch 39/150\n",
            "296/296 [==============================] - 62s 210ms/step - loss: 0.0122 - accuracy: 0.9966 - val_loss: 1.6451 - val_accuracy: 0.7752\n",
            "Epoch 40/150\n",
            "296/296 [==============================] - 62s 210ms/step - loss: 0.0104 - accuracy: 0.9974 - val_loss: 1.6695 - val_accuracy: 0.7750\n",
            "Epoch 41/150\n",
            "296/296 [==============================] - 62s 210ms/step - loss: 0.0104 - accuracy: 0.9971 - val_loss: 1.7172 - val_accuracy: 0.7731\n",
            "Epoch 42/150\n",
            "296/296 [==============================] - 62s 209ms/step - loss: 0.0104 - accuracy: 0.9972 - val_loss: 1.7148 - val_accuracy: 0.7748\n",
            "Epoch 43/150\n",
            "296/296 [==============================] - 62s 210ms/step - loss: 0.0096 - accuracy: 0.9975 - val_loss: 1.7819 - val_accuracy: 0.7708\n",
            "Epoch 44/150\n",
            "296/296 [==============================] - 62s 210ms/step - loss: 0.0112 - accuracy: 0.9969 - val_loss: 1.7698 - val_accuracy: 0.7742\n",
            "Epoch 45/150\n",
            "296/296 [==============================] - 62s 211ms/step - loss: 0.0079 - accuracy: 0.9981 - val_loss: 1.7653 - val_accuracy: 0.7745\n",
            "Epoch 46/150\n",
            "296/296 [==============================] - 62s 210ms/step - loss: 0.0060 - accuracy: 0.9989 - val_loss: 1.8165 - val_accuracy: 0.7735\n",
            "Epoch 47/150\n",
            "296/296 [==============================] - 62s 210ms/step - loss: 0.0064 - accuracy: 0.9988 - val_loss: 1.8097 - val_accuracy: 0.7755\n",
            "Epoch 48/150\n",
            "296/296 [==============================] - 62s 210ms/step - loss: 0.0065 - accuracy: 0.9985 - val_loss: 1.8265 - val_accuracy: 0.7756\n",
            "Epoch 49/150\n",
            "296/296 [==============================] - 62s 210ms/step - loss: 0.0054 - accuracy: 0.9992 - val_loss: 1.8401 - val_accuracy: 0.7756\n",
            "Epoch 50/150\n",
            "296/296 [==============================] - 62s 210ms/step - loss: 0.0045 - accuracy: 0.9995 - val_loss: 1.8600 - val_accuracy: 0.7745\n",
            "Epoch 51/150\n",
            "296/296 [==============================] - 62s 210ms/step - loss: 0.0041 - accuracy: 0.9996 - val_loss: 1.8765 - val_accuracy: 0.7756\n",
            "Epoch 52/150\n",
            "296/296 [==============================] - 62s 210ms/step - loss: 0.0038 - accuracy: 0.9995 - val_loss: 1.8885 - val_accuracy: 0.7761\n",
            "Epoch 53/150\n",
            "296/296 [==============================] - 62s 210ms/step - loss: 0.0033 - accuracy: 0.9996 - val_loss: 1.9141 - val_accuracy: 0.7731\n",
            "Epoch 54/150\n",
            "296/296 [==============================] - 62s 210ms/step - loss: 0.0031 - accuracy: 0.9997 - val_loss: 1.9214 - val_accuracy: 0.7756\n",
            "Epoch 55/150\n",
            "296/296 [==============================] - 62s 210ms/step - loss: 0.0024 - accuracy: 0.9998 - val_loss: 1.9336 - val_accuracy: 0.7752\n",
            "Epoch 56/150\n",
            "296/296 [==============================] - 62s 210ms/step - loss: 0.0022 - accuracy: 0.9999 - val_loss: 1.9484 - val_accuracy: 0.7755\n",
            "Epoch 57/150\n",
            "296/296 [==============================] - 62s 210ms/step - loss: 0.0021 - accuracy: 0.9999 - val_loss: 1.9690 - val_accuracy: 0.7749\n",
            "Epoch 58/150\n",
            "296/296 [==============================] - 62s 210ms/step - loss: 0.0020 - accuracy: 1.0000 - val_loss: 2.0900 - val_accuracy: 0.7740\n",
            "Epoch 59/150\n",
            "296/296 [==============================] - 62s 210ms/step - loss: 0.0152 - accuracy: 0.9963 - val_loss: 1.9647 - val_accuracy: 0.7749\n",
            "Epoch 60/150\n",
            "296/296 [==============================] - 62s 210ms/step - loss: 0.0056 - accuracy: 0.9986 - val_loss: 1.9686 - val_accuracy: 0.7758\n",
            "Epoch 61/150\n",
            "296/296 [==============================] - 62s 210ms/step - loss: 0.0035 - accuracy: 0.9994 - val_loss: 1.9826 - val_accuracy: 0.7752\n",
            "Epoch 62/150\n",
            "296/296 [==============================] - 62s 210ms/step - loss: 0.0028 - accuracy: 0.9996 - val_loss: 1.9900 - val_accuracy: 0.7754\n",
            "Epoch 63/150\n",
            "296/296 [==============================] - 62s 210ms/step - loss: 0.0017 - accuracy: 0.9999 - val_loss: 2.0026 - val_accuracy: 0.7756\n",
            "Epoch 64/150\n",
            "296/296 [==============================] - 62s 210ms/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 2.0157 - val_accuracy: 0.7755\n",
            "Epoch 65/150\n",
            "296/296 [==============================] - 62s 210ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 2.0263 - val_accuracy: 0.7755\n",
            "Epoch 66/150\n",
            "296/296 [==============================] - 62s 210ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 2.0381 - val_accuracy: 0.7751\n",
            "Epoch 67/150\n",
            "296/296 [==============================] - 62s 210ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 2.0453 - val_accuracy: 0.7752\n",
            "Epoch 68/150\n",
            "296/296 [==============================] - 62s 210ms/step - loss: 0.0010 - accuracy: 1.0000 - val_loss: 2.0547 - val_accuracy: 0.7754\n",
            "Epoch 69/150\n",
            "296/296 [==============================] - 62s 210ms/step - loss: 0.0010 - accuracy: 1.0000 - val_loss: 2.0653 - val_accuracy: 0.7755\n",
            "Epoch 70/150\n",
            "296/296 [==============================] - 62s 210ms/step - loss: 9.1208e-04 - accuracy: 1.0000 - val_loss: 2.0731 - val_accuracy: 0.7753\n",
            "Epoch 71/150\n",
            "296/296 [==============================] - 62s 211ms/step - loss: 9.2646e-04 - accuracy: 1.0000 - val_loss: 2.0828 - val_accuracy: 0.7750\n",
            "Epoch 72/150\n",
            "296/296 [==============================] - 62s 210ms/step - loss: 8.6561e-04 - accuracy: 1.0000 - val_loss: 2.0889 - val_accuracy: 0.7753\n",
            "Epoch 73/150\n",
            "296/296 [==============================] - 62s 211ms/step - loss: 8.1480e-04 - accuracy: 1.0000 - val_loss: 2.0951 - val_accuracy: 0.7754\n",
            "Epoch 74/150\n",
            "296/296 [==============================] - 63s 211ms/step - loss: 7.6678e-04 - accuracy: 1.0000 - val_loss: 2.1022 - val_accuracy: 0.7753\n",
            "Epoch 75/150\n",
            "296/296 [==============================] - 62s 211ms/step - loss: 7.6496e-04 - accuracy: 1.0000 - val_loss: 2.1102 - val_accuracy: 0.7754\n",
            "Epoch 76/150\n",
            "296/296 [==============================] - 62s 211ms/step - loss: 7.3615e-04 - accuracy: 1.0000 - val_loss: 2.1174 - val_accuracy: 0.7748\n",
            "Epoch 77/150\n",
            "296/296 [==============================] - 62s 211ms/step - loss: 6.7733e-04 - accuracy: 1.0000 - val_loss: 2.1228 - val_accuracy: 0.7754\n",
            "Epoch 78/150\n",
            "296/296 [==============================] - 62s 211ms/step - loss: 7.0373e-04 - accuracy: 1.0000 - val_loss: 2.1285 - val_accuracy: 0.7750\n",
            "Epoch 79/150\n",
            "296/296 [==============================] - 62s 211ms/step - loss: 6.6594e-04 - accuracy: 1.0000 - val_loss: 2.1357 - val_accuracy: 0.7753\n",
            "Epoch 80/150\n",
            "296/296 [==============================] - 62s 210ms/step - loss: 6.3370e-04 - accuracy: 1.0000 - val_loss: 2.1407 - val_accuracy: 0.7750\n",
            "Epoch 81/150\n",
            "296/296 [==============================] - 62s 210ms/step - loss: 6.1628e-04 - accuracy: 1.0000 - val_loss: 2.1477 - val_accuracy: 0.7751\n",
            "Epoch 82/150\n",
            "296/296 [==============================] - 62s 210ms/step - loss: 5.9708e-04 - accuracy: 1.0000 - val_loss: 2.1536 - val_accuracy: 0.7756\n",
            "Epoch 83/150\n",
            "296/296 [==============================] - 62s 210ms/step - loss: 6.0066e-04 - accuracy: 1.0000 - val_loss: 2.1592 - val_accuracy: 0.7753\n",
            "Epoch 84/150\n",
            "296/296 [==============================] - 62s 209ms/step - loss: 5.4972e-04 - accuracy: 1.0000 - val_loss: 2.1645 - val_accuracy: 0.7754\n",
            "Epoch 85/150\n",
            "296/296 [==============================] - 62s 211ms/step - loss: 5.5216e-04 - accuracy: 1.0000 - val_loss: 2.1686 - val_accuracy: 0.7752\n",
            "Epoch 86/150\n",
            "296/296 [==============================] - 62s 211ms/step - loss: 5.2576e-04 - accuracy: 1.0000 - val_loss: 2.1740 - val_accuracy: 0.7750\n",
            "Epoch 87/150\n",
            "296/296 [==============================] - 62s 210ms/step - loss: 5.3277e-04 - accuracy: 1.0000 - val_loss: 2.1798 - val_accuracy: 0.7753\n",
            "Epoch 88/150\n",
            "296/296 [==============================] - 63s 211ms/step - loss: 5.0263e-04 - accuracy: 1.0000 - val_loss: 2.1850 - val_accuracy: 0.7749\n",
            "Epoch 89/150\n",
            "296/296 [==============================] - 62s 210ms/step - loss: 5.2935e-04 - accuracy: 1.0000 - val_loss: 2.1890 - val_accuracy: 0.7752\n",
            "Epoch 90/150\n",
            "296/296 [==============================] - 62s 209ms/step - loss: 4.6653e-04 - accuracy: 1.0000 - val_loss: 2.1946 - val_accuracy: 0.7754\n",
            "Epoch 91/150\n",
            "296/296 [==============================] - 62s 209ms/step - loss: 4.7133e-04 - accuracy: 1.0000 - val_loss: 2.1998 - val_accuracy: 0.7756\n",
            "Epoch 92/150\n",
            "296/296 [==============================] - 62s 209ms/step - loss: 4.4770e-04 - accuracy: 1.0000 - val_loss: 2.2026 - val_accuracy: 0.7756\n",
            "Epoch 93/150\n",
            "296/296 [==============================] - 61s 208ms/step - loss: 4.6626e-04 - accuracy: 1.0000 - val_loss: 2.2080 - val_accuracy: 0.7752\n",
            "Epoch 94/150\n",
            "296/296 [==============================] - 61s 207ms/step - loss: 4.3800e-04 - accuracy: 1.0000 - val_loss: 2.2122 - val_accuracy: 0.7751\n",
            "Epoch 95/150\n",
            "296/296 [==============================] - 61s 207ms/step - loss: 4.3276e-04 - accuracy: 1.0000 - val_loss: 2.2165 - val_accuracy: 0.7754\n",
            "Epoch 96/150\n",
            "296/296 [==============================] - 62s 210ms/step - loss: 4.2847e-04 - accuracy: 1.0000 - val_loss: 2.2198 - val_accuracy: 0.7749\n",
            "Epoch 97/150\n",
            "296/296 [==============================] - 62s 210ms/step - loss: 4.0128e-04 - accuracy: 1.0000 - val_loss: 2.2246 - val_accuracy: 0.7751\n",
            "Epoch 98/150\n",
            "296/296 [==============================] - 61s 207ms/step - loss: 3.9703e-04 - accuracy: 1.0000 - val_loss: 2.2287 - val_accuracy: 0.7754\n",
            "Epoch 99/150\n",
            "296/296 [==============================] - 62s 211ms/step - loss: 3.9437e-04 - accuracy: 1.0000 - val_loss: 2.2325 - val_accuracy: 0.7750\n",
            "Epoch 100/150\n",
            "296/296 [==============================] - 61s 208ms/step - loss: 3.8494e-04 - accuracy: 1.0000 - val_loss: 2.2368 - val_accuracy: 0.7744\n",
            "Epoch 101/150\n",
            "296/296 [==============================] - 61s 207ms/step - loss: 3.8173e-04 - accuracy: 1.0000 - val_loss: 2.2394 - val_accuracy: 0.7748\n",
            "Epoch 102/150\n",
            "296/296 [==============================] - 61s 208ms/step - loss: 3.6486e-04 - accuracy: 1.0000 - val_loss: 2.2440 - val_accuracy: 0.7753\n",
            "Epoch 103/150\n",
            "296/296 [==============================] - 62s 209ms/step - loss: 3.6218e-04 - accuracy: 1.0000 - val_loss: 2.2476 - val_accuracy: 0.7747\n",
            "Epoch 104/150\n",
            "296/296 [==============================] - 61s 207ms/step - loss: 3.5731e-04 - accuracy: 1.0000 - val_loss: 2.2516 - val_accuracy: 0.7754\n",
            "Epoch 105/150\n",
            "296/296 [==============================] - 62s 208ms/step - loss: 3.5597e-04 - accuracy: 1.0000 - val_loss: 2.2559 - val_accuracy: 0.7753\n",
            "Epoch 106/150\n",
            "296/296 [==============================] - 61s 208ms/step - loss: 3.3955e-04 - accuracy: 1.0000 - val_loss: 2.2580 - val_accuracy: 0.7747\n",
            "Epoch 107/150\n",
            "296/296 [==============================] - 61s 207ms/step - loss: 3.3579e-04 - accuracy: 1.0000 - val_loss: 2.2618 - val_accuracy: 0.7750\n",
            "Epoch 108/150\n",
            "296/296 [==============================] - 61s 207ms/step - loss: 3.3146e-04 - accuracy: 1.0000 - val_loss: 2.2653 - val_accuracy: 0.7751\n",
            "Epoch 109/150\n",
            "296/296 [==============================] - 62s 211ms/step - loss: 3.2909e-04 - accuracy: 1.0000 - val_loss: 2.2688 - val_accuracy: 0.7753\n",
            "Epoch 110/150\n",
            "296/296 [==============================] - 62s 209ms/step - loss: 3.1824e-04 - accuracy: 1.0000 - val_loss: 2.2713 - val_accuracy: 0.7750\n",
            "Epoch 111/150\n",
            "296/296 [==============================] - 61s 207ms/step - loss: 3.1667e-04 - accuracy: 1.0000 - val_loss: 2.2751 - val_accuracy: 0.7750\n",
            "Epoch 112/150\n",
            "296/296 [==============================] - 62s 210ms/step - loss: 3.0447e-04 - accuracy: 1.0000 - val_loss: 2.2781 - val_accuracy: 0.7748\n",
            "Epoch 113/150\n",
            "296/296 [==============================] - 62s 210ms/step - loss: 3.1495e-04 - accuracy: 1.0000 - val_loss: 2.2816 - val_accuracy: 0.7748\n",
            "Epoch 114/150\n",
            "296/296 [==============================] - 63s 212ms/step - loss: 3.0541e-04 - accuracy: 1.0000 - val_loss: 2.2848 - val_accuracy: 0.7749\n",
            "Epoch 115/150\n",
            "296/296 [==============================] - 61s 207ms/step - loss: 2.9283e-04 - accuracy: 1.0000 - val_loss: 2.2874 - val_accuracy: 0.7749\n",
            "Epoch 116/150\n",
            "296/296 [==============================] - 62s 210ms/step - loss: 3.0223e-04 - accuracy: 1.0000 - val_loss: 2.2910 - val_accuracy: 0.7749\n",
            "Epoch 117/150\n",
            "296/296 [==============================] - 62s 210ms/step - loss: 2.8169e-04 - accuracy: 1.0000 - val_loss: 2.2936 - val_accuracy: 0.7747\n",
            "Epoch 118/150\n",
            "296/296 [==============================] - 62s 208ms/step - loss: 2.8660e-04 - accuracy: 1.0000 - val_loss: 2.2968 - val_accuracy: 0.7747\n",
            "Epoch 119/150\n",
            "296/296 [==============================] - 61s 208ms/step - loss: 2.8137e-04 - accuracy: 1.0000 - val_loss: 2.2993 - val_accuracy: 0.7746\n",
            "Epoch 120/150\n",
            "296/296 [==============================] - 62s 208ms/step - loss: 2.7872e-04 - accuracy: 1.0000 - val_loss: 2.3026 - val_accuracy: 0.7747\n",
            "Epoch 121/150\n",
            "296/296 [==============================] - 61s 208ms/step - loss: 2.6658e-04 - accuracy: 1.0000 - val_loss: 2.3054 - val_accuracy: 0.7749\n",
            "Epoch 122/150\n",
            "296/296 [==============================] - 62s 208ms/step - loss: 2.6860e-04 - accuracy: 1.0000 - val_loss: 2.3080 - val_accuracy: 0.7744\n",
            "Epoch 123/150\n",
            "296/296 [==============================] - 62s 210ms/step - loss: 2.6064e-04 - accuracy: 1.0000 - val_loss: 2.3118 - val_accuracy: 0.7748\n",
            "Epoch 124/150\n",
            "296/296 [==============================] - 62s 211ms/step - loss: 2.5089e-04 - accuracy: 1.0000 - val_loss: 2.3136 - val_accuracy: 0.7748\n",
            "Epoch 125/150\n",
            "296/296 [==============================] - 62s 210ms/step - loss: 2.5282e-04 - accuracy: 1.0000 - val_loss: 2.3168 - val_accuracy: 0.7748\n",
            "Epoch 126/150\n",
            "296/296 [==============================] - 62s 209ms/step - loss: 2.4781e-04 - accuracy: 1.0000 - val_loss: 2.3191 - val_accuracy: 0.7746\n",
            "Epoch 127/150\n",
            "296/296 [==============================] - 62s 209ms/step - loss: 2.5482e-04 - accuracy: 1.0000 - val_loss: 2.3220 - val_accuracy: 0.7749\n",
            "Epoch 128/150\n",
            "296/296 [==============================] - 62s 209ms/step - loss: 2.4219e-04 - accuracy: 1.0000 - val_loss: 2.3247 - val_accuracy: 0.7748\n",
            "Epoch 129/150\n",
            "296/296 [==============================] - 62s 209ms/step - loss: 2.4429e-04 - accuracy: 1.0000 - val_loss: 2.3266 - val_accuracy: 0.7749\n",
            "Epoch 130/150\n",
            "296/296 [==============================] - 62s 209ms/step - loss: 2.3764e-04 - accuracy: 1.0000 - val_loss: 2.3300 - val_accuracy: 0.7747\n",
            "Epoch 131/150\n",
            "296/296 [==============================] - 62s 209ms/step - loss: 2.3052e-04 - accuracy: 1.0000 - val_loss: 2.3323 - val_accuracy: 0.7745\n",
            "Epoch 132/150\n",
            "296/296 [==============================] - 62s 209ms/step - loss: 2.2620e-04 - accuracy: 1.0000 - val_loss: 2.3350 - val_accuracy: 0.7747\n",
            "Epoch 133/150\n",
            "296/296 [==============================] - 62s 209ms/step - loss: 2.2532e-04 - accuracy: 1.0000 - val_loss: 2.3369 - val_accuracy: 0.7746\n",
            "Epoch 134/150\n",
            "296/296 [==============================] - 62s 208ms/step - loss: 2.2861e-04 - accuracy: 1.0000 - val_loss: 2.3397 - val_accuracy: 0.7747\n",
            "Epoch 135/150\n",
            "296/296 [==============================] - 62s 209ms/step - loss: 2.2556e-04 - accuracy: 1.0000 - val_loss: 2.3418 - val_accuracy: 0.7745\n",
            "Epoch 136/150\n",
            "296/296 [==============================] - 62s 208ms/step - loss: 2.2590e-04 - accuracy: 1.0000 - val_loss: 2.3440 - val_accuracy: 0.7747\n",
            "Epoch 137/150\n",
            "296/296 [==============================] - 61s 208ms/step - loss: 2.1460e-04 - accuracy: 1.0000 - val_loss: 2.3465 - val_accuracy: 0.7748\n",
            "Epoch 138/150\n",
            "296/296 [==============================] - 61s 208ms/step - loss: 2.1361e-04 - accuracy: 1.0000 - val_loss: 2.3492 - val_accuracy: 0.7746\n",
            "Epoch 139/150\n",
            "296/296 [==============================] - 62s 209ms/step - loss: 2.1576e-04 - accuracy: 1.0000 - val_loss: 2.3511 - val_accuracy: 0.7745\n",
            "Epoch 140/150\n",
            "296/296 [==============================] - 62s 210ms/step - loss: 2.1213e-04 - accuracy: 1.0000 - val_loss: 2.3533 - val_accuracy: 0.7747\n",
            "Epoch 141/150\n",
            "296/296 [==============================] - 62s 208ms/step - loss: 2.0324e-04 - accuracy: 1.0000 - val_loss: 2.3556 - val_accuracy: 0.7746\n",
            "Epoch 142/150\n",
            "296/296 [==============================] - 62s 209ms/step - loss: 2.0229e-04 - accuracy: 1.0000 - val_loss: 2.3583 - val_accuracy: 0.7748\n",
            "Epoch 143/150\n",
            "296/296 [==============================] - 62s 209ms/step - loss: 2.0009e-04 - accuracy: 1.0000 - val_loss: 2.3605 - val_accuracy: 0.7747\n",
            "Epoch 144/150\n",
            "296/296 [==============================] - 62s 208ms/step - loss: 1.9998e-04 - accuracy: 1.0000 - val_loss: 2.3623 - val_accuracy: 0.7746\n",
            "Epoch 145/150\n",
            "296/296 [==============================] - 62s 208ms/step - loss: 2.0835e-04 - accuracy: 1.0000 - val_loss: 2.3650 - val_accuracy: 0.7748\n",
            "Epoch 146/150\n",
            " 13/296 [>.............................] - ETA: 51s - loss: 2.2024e-04 - accuracy: 1.0000"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2azUUlebxBkS",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 189
        },
        "outputId": "50f005ee-ca49-4bf9-8704-b07a5068d2ed"
      },
      "source": [
        "k=hit.history\n",
        "print(k['accuracy'][0],k['val_accuracy'][0])\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-2-2c9b6b07e208>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mk\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mhit\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'accuracy'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'val_accuracy'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'hit' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "taDIFMfwug4e"
      },
      "source": [
        "l=[1,2,3,4,5,6]\n",
        "Tacrcy=[0.0256,]\n",
        "Vacrcy=[]\n",
        "plt.figure(1)\n",
        "plt.plot(l,Tacrcy,color='g',marker='o',linestyle='dashed')\n",
        "plt.plot(l,Vacrcy,color='r',marker='o',linestyle='dashed')\n",
        "plt.xlabel('No.of Conv Layers')\n",
        "plt.ylabel('accuracy')\n",
        "plt.title('Kernels:4,8,16,32,64,128')\n",
        "plt.legend(['Training','Validation'])\n",
        "plt.grid()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZYHRzSgiX04i"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "plt.plot(hit.history['loss'])\n",
        "plt.plot(hit.history['val_loss'])\n",
        "plt.title('loss vs epoch')\n",
        "plt.xlabel('epochs')\n",
        "plt.ylabel('loss')\n",
        "plt.legend(['training_loss','validation_loss'],loc='upper_right')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rhouEtIUX1FY"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "plt.plot(hit.history['accuracy'])\n",
        "plt.plot(hit.history['val_accuracy'])\n",
        "plt.title('accuracy vs epoch')\n",
        "plt.xlabel('epochs')\n",
        "plt.ylabel('accuracy')\n",
        "plt.legend(['training_accuracy','validation_accuracy'],loc='upper_right')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Kt1EUu4V2Yr3"
      },
      "source": [
        " import os\n",
        " \n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        " \n",
        "print(tf.version.VERSION)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pBDCMtqK2jV_"
      },
      "source": [
        " !pip install pyyaml h5py"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mFSZMmaW22F2"
      },
      "source": [
        " os.listdir(checkpoint_dir)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g-5E6KbV2_e-"
      },
      "source": [
        " model.evaluate(X_test,y_1hotTest,verbose=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "np2WaiQZ3EUW"
      },
      "source": [
        " pred=model.predict_classes(X_test[4].reshape(1,28,28,1))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CqlHW9Kv3JPw"
      },
      "source": [
        " model.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xNv81WS73Mx_"
      },
      "source": [
        " #######Confusion matrix\n",
        "labels_dict ={0:0,1:1,2:2,3:3,4:4,5:5,6:6,7:7,8:8,9:9,10:'A',11:'B',12:'C',\n",
        "              13:'D',14:'E',15:'F',16:'G',17:'H',18:'I',19:'J',20:'K',21:'l',\n",
        "              22:'M',23:'N',24:'O',25:'P',26:'Q',27:'R',28:'S',\n",
        "              29:'T',30:'u',31:'V',32:'W',33:'X',34:'Y',35:'Z',36:'a',37:'b',\n",
        "              38:'d',39:'e',40:'f',41:'g',42:'h',43:'n',44:'q',45:'r',46:'t'}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R9ZDsBL63QhF"
      },
      "source": [
        " List=labels_dict.values()\n",
        "class_names=list(List)\n",
        "print(class_names)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dhcSqOEs3T4E"
      },
      "source": [
        " import io\n",
        "import itertools\n",
        "import numpy as np\n",
        "import sklearn.metrics\n",
        "import tensorflow as tf\n",
        "import matplotlib.pyplot as plt\n",
        " \n",
        "from tensorflow import keras\n",
        "from datetime import datetime\n",
        " \n",
        "%load_ext tensorboard"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ir_HIsiT3lHv"
      },
      "source": [
        " from sklearn.metrics import classification_report, confusion_matrix"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wih3AnX03miU"
      },
      "source": [
        " y_predicts=model.predict(X_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4y8B0c0n3q_t"
      },
      "source": [
        " cm=confusion_matrix(y_1hotTest.argmax(axis=1),y_predicts.argmax(axis=1))\n",
        "print(cm.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E9_G-mjk3uoN"
      },
      "source": [
        " print(cm)\n",
        "plt.imshow(cm)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fDvpeSaH3zWN"
      },
      "source": [
        "    figure = plt.figure(figsize=(20, 15))\n",
        "    plt.imshow(cm,cmap=plt.cm.Blues)#     interpolation='nearest', cmap=plt.cm.Blues)\n",
        "    plt.title(\"Confusion matrix\")\n",
        "    plt.colorbar()\n",
        "    tick_marks = np.arange(len(class_names))\n",
        "    plt.xticks(tick_marks, class_names, rotation=45)\n",
        "    plt.yticks(tick_marks, class_names)\n",
        "     # Normalize the confusion matrix.\n",
        "    cm = np.around(cm.astype('float') / cm.sum(axis=1)[:, np.newaxis], decimals=2)\n",
        "    \n",
        "    # Use white text if squares are dark; otherwise black.\n",
        "    threshold = cm.max() / 2.\n",
        "    \n",
        "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
        "        color = \"white\" if cm[i, j] > threshold else \"black\"\n",
        "        plt.text(j, i, cm[i, j], horizontalalignment=\"center\", color=color)\n",
        "        \n",
        "    plt.tight_layout()\n",
        "    plt.ylabel('True label')\n",
        "    plt.xlabel('Predicted label')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_XgJAnWR37V2"
      },
      "source": [
        " print( np.around(cm.astype('float') / cm.sum(axis=1)[:, np.newaxis], decimals=2))"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}